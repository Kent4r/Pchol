Если ваш датасет представлен в виде папок с классами, внутри которых лежат изображения (стандартная структура для задач классификации изображений), то подготовка данных будет включать **загрузку изображений, их предобработку и разбиение на train/val**.

### **1. Структура датасета**

Пример структуры:

```
dataset/
├── class_1/
│   ├── img1.jpg
│   ├── img2.jpg
│   └── ...
├── class_2/
│   ├── img1.jpg
│   └── ...
└── ...
```

### **2. Подготовка данных**

#### **Шаг 1: Загрузка изображений и разметка**

Используем `ImageDataGenerator` из `tensorflow.keras` (удобно для работы с изображениями) или `torchvision.datasets.ImageFolder` для PyTorch.

##### **Вариант 1: TensorFlow/Keras**

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Укажите путь к папке с данными
data_dir = 'путь/к/dataset/'

# Создаём генератор данных с аугментацией (опционально)
datagen = ImageDataGenerator(
    rescale=1./255,          # нормализация пикселей [0, 1]
    validation_split=0.2,    # доля валидационной выборки
    rotation_range=20,       # аугментация: поворот
    width_shift_range=0.2,   # аугментация: сдвиг по ширине
    horizontal_flip=True     # аугментация: отражение по горизонтали
)

# Загрузка train и val данных
train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(224, 224),  # размер изображений (например, для ResNet)
    batch_size=32,
    class_mode='categorical',
    subset='training',       # выборка для обучения
    seed=42                  # фиксируем random_state
)

val_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation',     # выборка для валидации
    seed=42
)
```

##### **Вариант 2: PyTorch**

```python
import torch
from torchvision import datasets, transforms

# Определяем трансформации (аугментация + нормализация)
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Загружаем данные
train_data = datasets.ImageFolder(
    root='путь/к/dataset/',
    transform=train_transform
)

val_data = datasets.ImageFolder(
    root='путь/к/dataset/',
    transform=val_transform
)

# Разделяем на train/val (если нет встроенного split)
from torch.utils.data import random_split

val_size = int(0.2 * len(train_data))  # 20% на валидацию
train_size = len(train_data) - val_size
train_dataset, val_dataset = random_split(
    train_data, 
    [train_size, val_size],
    generator=torch.Generator().manual_seed(42)  # аналог random_state
)

# Создаём DataLoader
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)
```

#### **Шаг 2: Проверка баланса классов**

Убедитесь, что классы распределены равномерно:

```python
import os
import matplotlib.pyplot as plt

# Подсчёт числа изображений в каждом классе
class_counts = {}
for class_name in os.listdir(data_dir):
    class_dir = os.path.join(data_dir, class_name)
    if os.path.isdir(class_dir):
        class_counts[class_name] = len(os.listdir(class_dir))

# Визуализация
plt.bar(class_counts.keys(), class_counts.values())
plt.title('Распределение классов')
plt.show()
```

#### **Шаг 3: Сохранение разметки (опционально)**

Если нужно сохранить пути к изображениям и их метки в CSV:

```python
import pandas as pd

data = []
for class_name in os.listdir(data_dir):
    class_dir = os.path.join(data_dir, class_name)
    if os.path.isdir(class_dir):
        for img_name in os.listdir(class_dir):
            data.append({
                'image_path': os.path.join(class_dir, img_name),
                'label': class_name
            })

df = pd.DataFrame(data)
df.to_csv('dataset_labels.csv', index=False)
```

### **3. Важные моменты**

- **Аугментация** – помогает увеличить разнообразие данных (особенно если датасет маленький).
- **Нормализация** – приводит значения пикселей к одному масштабу (например, `[0, 1]` или стандартный нормализованный вид).
- **Фиксация `random_state`/`seed`** – для воспроизводимости экспериментов.
- **Стратификация** – если классы несбалансированы, лучше использовать стратифицированное разбиение (в `ImageDataGenerator` это делается автоматически).

### **Вывод**

- Для **TensorFlow/Keras** используйте `ImageDataGenerator` + `flow_from_directory`.
- Для **PyTorch** – `ImageFolder` + `random_split` или `SubsetRandomSampler`.
- Всегда проверяйте баланс классов и применяйте аугментацию, если данных мало.

Если у вас есть специфичные требования (например, кастомная аугментация или работа с градациями серого), уточните – помогу адаптировать код!

### **Yolo**

```
yolo classify train model=yolov8s-cls.pt data=dataset/train epochs=6 imgsz=224
```

Заменяет всю подготовку данных, так как делает это самостоятельно

